{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI:  asp2197\n",
    "* Name: Abhay Pawar\n",
    "\n",
    "### Team Member 2 [optional]:\n",
    "* UNI:  vb2424\n",
    "* Name: Vijay Balaji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import f_regression,RFE,RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data.csv\")\n",
    "holdout = pd.read_csv(\"data/holdout.csv\")\n",
    "data.head()\n",
    "\n",
    "sub=data.subscribed.copy().as_matrix()\n",
    "data.drop(['subscribed'],axis=1,inplace=True)\n",
    "hold_ids=holdout.ID.copy()\n",
    "holdout.drop(['ID'],axis=1,inplace=True)\n",
    "y=np.zeros(len(sub))\n",
    "for i in range(len(sub)):\n",
    "    if sub[i]=='no':\n",
    "        y[i]=0\n",
    "    elif sub[i]=='yes':\n",
    "        y[i]=1\n",
    "        \n",
    "data.drop(['duration'],axis=1,inplace=True)\n",
    "holdout.drop(['duration'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did initial exploration of the data in excel using pivot tables and filters as it is much more convenient. We realized that the train and holdout data don't have the same categories for some categorical variables. We compared the categories in these variables in train and holdout data and did grouping so that both datasets have same categories. The grouping was done by looking at every categorical feature individually and grouping catgories which have very similar event rates. Following code does the grouping.\n",
    "We also checked if there are any outliers. There are no outliers in the continuous features. prev_days had a value 999 which means that customer wasn't contacted. We have converted this feature into a binary and tells if the customer was contacted or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loangroup(dataset):\n",
    "    temp = dataset['loan'].copy()\n",
    "    temp[dataset['loan']=='unknown'] = 'no'\n",
    "    dataset['loan'] = temp\n",
    "def housinggroup(dataset):\n",
    "    temp = dataset['housing'].copy()\n",
    "    temp[dataset['housing']=='unknown'] = 'yes'\n",
    "    dataset['housing'] = temp\n",
    "def credit_defaultgroup(dataset):\n",
    "    temp = dataset['credit_default']\n",
    "    temp[dataset['credit_default']=='unknown'] = 'yes'\n",
    "    dataset['credit_default'] = temp\n",
    "def educationgroup(dataset):\n",
    "    temp = dataset['education'].copy()\n",
    "    temp[dataset['education']=='unknown'] = 'illiterate'\n",
    "    dataset['education'] = temp\n",
    "def jobgroup(dataset):\n",
    "    temp = dataset['job'].copy()\n",
    "    temp[dataset['job']=='unknown'] = 'technician'\n",
    "    temp[dataset['job']=='housemaid'] = 'technician'\n",
    "    temp[dataset['job']=='entrepreneur'] = 'services'\n",
    "    dataset['job'] = temp\n",
    "def maritalgroup(dataset):\n",
    "    temp = dataset['marital_status'].copy()\n",
    "    temp[dataset['marital_status']=='unknown'] = 'single'\n",
    "    dataset['marital_status'] = temp\n",
    "\n",
    "def campaigngroup(dataset):\n",
    "    temp = dataset['campaign'].copy()\n",
    "    temp[dataset['campaign']<5] = 1\n",
    "    temp[(dataset['campaign']<8) & (dataset['campaign']>=5)] = 2\n",
    "    temp[dataset['campaign']>=8] = 3\n",
    "    dataset['campaign'] = temp\n",
    "    dataset['campaign'] = dataset['campaign'].astype('category')\n",
    "    \n",
    "def monthgroup(dataset):\n",
    "    temp = dataset['month'].copy()\n",
    "    temp[dataset['month']=='nov'] = 'jun'\n",
    "    temp[dataset['month']=='aug'] = 'jun'\n",
    "    dataset['month'] = temp\n",
    "\n",
    "def prev_daysgroup(dataset):\n",
    "    temp = dataset['prev_days'].copy()\n",
    "    temp.iloc[np.where(dataset['prev_days']!=999)] = 0\n",
    "    temp.iloc[np.where(dataset['prev_days']==999)] = 1\n",
    "    dataset['prev_days_binary'] = temp    \n",
    "\n",
    "def agegroup(dataset):\n",
    "    temp=dataset['age'].copy()\n",
    "    temp[dataset['age']<=20] = 20\n",
    "    temp[(dataset['age']>20) & (dataset['age']<=26)] = 26\n",
    "    temp[(dataset['age']>26) & (dataset['age']<=30)] = 30\n",
    "    temp[(dataset['age']>30) & (dataset['age']<=38)] = 38\n",
    "    temp[(dataset['age']>38) & (dataset['age']<=51)] = 51\n",
    "    temp[(dataset['age']>51) & (dataset['age']<=61)] = 61\n",
    "    temp[dataset['age']>61] = 62\n",
    "    dataset['age_group']=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "loangroup(data)\n",
    "loangroup(holdout)\n",
    "housinggroup(data)\n",
    "housinggroup(holdout)\n",
    "credit_defaultgroup(data)\n",
    "credit_defaultgroup(holdout)\n",
    "educationgroup(data)\n",
    "educationgroup(holdout)\n",
    "jobgroup(data)\n",
    "jobgroup(holdout)\n",
    "maritalgroup(data)\n",
    "maritalgroup(holdout)\n",
    "campaigngroup(data)\n",
    "campaigngroup(holdout)\n",
    "monthgroup(data)\n",
    "monthgroup(holdout)\n",
    "prev_daysgroup(data)\n",
    "prev_daysgroup(holdout)\n",
    "agegroup(data)\n",
    "agegroup(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = ['age_group','job','marital_status','education','prev_outcomes','month','contact','campaign','day_of_week']\n",
    "for c in cat:\n",
    "    data[c] = data[c].astype('category')\n",
    "    holdout[c] = holdout[c].astype('category')\n",
    "X = pd.get_dummies(data)\n",
    "X_holdout = pd.get_dummies(holdout)\n",
    "X=X.drop(X.columns[[29, 31,33,35]],axis=1)\n",
    "X_holdout=X_holdout.drop(X_holdout.columns[[29, 31,33,35]],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here.\n",
    "\n",
    "Feature Engineering/Selection: \n",
    "\n",
    "We tried to create a new feature using prev_days and prev_outcome. Reason being that customers with prev_days==999 have prev_outcome as unknown and hence, there is high correlation. But, this feature did not add any improvement in logistic regression and hence, we decided to not use it. We converted prev_days into a binary variable for logistic regression as 999 value is too high. We used prev_days as it is for tree based models as 999 value wouldn't affect the results.\n",
    "\n",
    "We tried using the F scores from f_classif and RFECV to select the features. RFECV gave better results and hence, we have used it for all the models.\n",
    "\n",
    "Validation:\n",
    "Since, cross-val-score computes scores on random splits on data, we initially created a single 20% test data to check the performance of models. But, improvement in AUC on this test data didn't necessarily convert into improvement on the holdout on Leaderboard. So, we shifted to using cross_val_score. \n",
    "\n",
    "Classifiers used:\n",
    "We used logistic regression, KNN, Naive bayes in this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F scores\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=11)\n",
    "F,p=feature_selection.f_classif(X_train.as_matrix(),y_train)\n",
    "Fscore=pd.DataFrame(X_train.columns)\n",
    "Fscore['F_value']=F\n",
    "Fscore['p_value']=p\n",
    "#Fscore.to_csv('Dummies_fscore.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression we first selected the features using RFECV and then used gridsearch to find optimal C with l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False False  True False False False  True False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False  True False False False  True  True  True False\n",
      "  True  True  True False False  True False False False  True False  True\n",
      "  True  True  True  True False False  True  True  True False]\n",
      "[33 36  1 24 32 25  1 34 38 11  1 18  1 15 22  5 29 30 27 19 12 28  9  4  3\n",
      " 31  8 20  1 21 37  7  1  1  1  6  1  1  1 35 26  1 16 17 14  1 13  1  1  1\n",
      "  1  1 23  2  1  1  1 10]\n"
     ]
    }
   ],
   "source": [
    "#RFECV on logistic regression\n",
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=2,scoring='roc_auc')\n",
    "selector = selector.fit(X_train, y_train)\n",
    "print selector.support_ \n",
    "print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False False  True False False False  True False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False  True False False False  True  True  True False\n",
      "  True  True  True False False  True False False False  True False  True\n",
      "  True  True  True  True False False  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "print selector.support_\n",
    "k=[]\n",
    "for i in range(len(selector.support_)):\n",
    "    if selector.support_[i]==False:\n",
    "        k.append(i)\n",
    "#k contains the columns to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-eaa6f571d2e7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-eaa6f571d2e7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    gd.fit(data.drop(data.columns[[k]],axis=1),y)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "param_grid={'logisticregression__C':np.arange(0.001,0.02,0.002)}\n",
    "gd=GridSearchCV(LogisticRegression(penalty='l2',param_grid=param_grid,scoring='roc_auc',cv=3)\n",
    "gd.fit(X.drop(data.columns[[k]],axis=1),y)\n",
    "gd.best_params_ \n",
    "#lr=LogisticRegression()\n",
    "#lr.fit(data.drop(data.columns[[k]],axis=1),y)\n",
    "#plr=make_pipeline(StandardScaler(),lr)\n",
    "#plr.fit(data_train.drop(data_train.columns[[k]],axis=1),y_train)\n",
    "#lr.fit(data_train,y_train)\n",
    "#y_predict_lr = lr.predict_proba(data_test)\n",
    "#print roc_auc_score(y_test,y_predict_lr[:,1])\n",
    "#scores=cross_val_score(lr,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "#scores\n",
    "#scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=make_pipeline(StandardScaler(),LogisticRegression(penalty='l2',C=0.005))\n",
    "scores=cross_val_score(lr,data.drop(data.columns[k],axis=1),y,cv=5,scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adaboost:\n",
    "sgd=SGDClassifier(loss='log', penalty='l2', alpha=1, l1_ratio=0.5, fit_intercept=True, n_iter=5, shuffle=True, verbose=0, \n",
    "              epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, \n",
    "              warm_start=False, average=False)\n",
    "abc=AdaBoostClassifier(base_estimator=SVC(), n_estimators=50, learning_rate=1.0, algorithm='SAMME', random_state=None)\n",
    "\n",
    "abc.fit(X_train,y_train)\n",
    "y_predict=abc.predict_proba(X_test)\n",
    "print roc_auc_score(y_test,y_predict[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, we tried with scaling the features. But, it gave worst results as compared to without scaling. Probable reason could be that high predictive features which should have higher weight get scaled down and hence, contribute as much as non-predictive features. Hence, worsening the performance. We also tried dropping low F score features, but it didn't give much improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761687824985\n",
      "0.831405324396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=40, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', \n",
    "                     metric_params=None, n_jobs=1)\n",
    "knn_pipe=make_pipeline(knn)\n",
    "knn_pipe.fit(X_train,y_train)\n",
    "y_predict_knn=knn.predict_proba(X_test)[:,1]\n",
    "y_predict_knn_train=knn.predict_proba(X_train)[:,1]\n",
    "\n",
    "print roc_auc_score(y_test,y_predict_knn)\n",
    "print roc_auc_score(y_train,y_predict_knn_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757314447918\n"
     ]
    }
   ],
   "source": [
    "#To run on holdout\n",
    "knn=KNeighborsClassifier(n_neighbors=25, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', \n",
    "                     metric_params=None, n_jobs=1)\n",
    "knn_pipe=make_pipeline(knn)\n",
    "knn_pipe.fit(X_train,y_train)\n",
    "y_predict_knn=knn_pipe.predict_proba(X_holdout_drop)[:,1]\n",
    "y_predict_knn_train=knn_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "print roc_auc_score(y_test,y_predict_knn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes: We used the gaussian assumption which won't be true for all the features. Still NB performs decent. We tried dropping features which are highly correlation. But, this did not much improvement. Only dropping one feature gave better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop on basis of F score: [41,15,10,31,32,45,28, ] var removed due to feature engineering: 1, 51, 55,2, 49\n",
    "#Drop due to correlation: 3,6\n",
    "#Due to binary: 28, 30,32,17,34\n",
    "\n",
    "#second stage low power: 29,53,42,16,43,25,24,23,17,12,44,20   18, 38, 4\n",
    "#Corr second stage: 46, 38, \n",
    "k=[46]\n",
    "X_drop=X.drop(X.columns[k],axis=1)\n",
    "X_holdout_drop=X_holdout.drop(X_holdout.columns[k],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_drop,y,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766064318262\n",
      "0.769425660311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "nbg=GaussianNB()\n",
    "#BernoulliNB\n",
    "#GaussianNB\n",
    "nbg.fit(X_train,y_train)\n",
    "y_predict_nbg=nbg.predict_proba(X_test)[:,1]\n",
    "y_predict_nbg_train=nbg.predict_proba(X_train)[:,1]\n",
    "print roc_auc_score(y_test,y_predict_nbg)\n",
    "print roc_auc_score(y_train,y_predict_nbg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles: We tried three different strategies to create ensemble model. \n",
    "1. Poor man's stacking: Building a model over the probabilities given by individual models\n",
    "2. Weighted averaging of probabilities from different model\n",
    "3. Weigthed average of rank of each customer from different models. Since, AUC depends only on how the customers are ranked by the probabilites, averaging the rank from probabilites from different models makes sense.\n",
    "2 and 3 gave improvement. 1 did not give much improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768728306176\n",
      "0.878260966781\n"
     ]
    }
   ],
   "source": [
    "#1. Poor man's stacking. Used GBC and logistic. Both, didn't give improvement.\n",
    "#X_train_ens=pd.DataFrame()\n",
    "X_train_ens=pd.DataFrame(y_pred_train_plr)\n",
    "X_train_ens.columns=['y_pred_train_plr']\n",
    "X_train_ens['y_predict_knn_train']=y_predict_knn_train\n",
    "X_train_ens['y_predict_nbg_train']=y_predict_nbg_train\n",
    "X_train_ens['y_pred_train_gbc']=y_pred_train_gbc\n",
    "X_train_ens.head()\n",
    "X_test_ens=pd.DataFrame(y_predict_plr)\n",
    "X_test_ens.columns=['y_predict_plr']\n",
    "X_test_ens['y_predict_knn_train']=y_predict_knn\n",
    "X_test_ens['y_predict_nbg_train']=y_predict_nbg\n",
    "X_test_ens['y_pred_train_gbc']=y_predict_gbc\n",
    "gbc1=GradientBoostingClassifier(loss='exponential', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                           min_samples_split=2, min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_depth=10, \n",
    "                           min_impurity_split=1e-07, init=None, random_state=11, max_features=None, verbose=0, \n",
    "                           max_leaf_nodes=20, warm_start=False, presort='auto')\n",
    "gbc1.fit(X_train_ens,y_train)\n",
    "y_predict_ens=gbc1.predict_proba(X_test_ens)[:,1]\n",
    "y_predict_ens_train=gbc1.predict_proba(X_train_ens)[:,1]\n",
    "\n",
    "print roc_auc_score(y_test,y_predict_ens)\n",
    "print roc_auc_score(y_train,y_predict_ens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794342804087 2 0 5\n"
     ]
    }
   ],
   "source": [
    "#Weighted average of probabilites\n",
    "auc_max=0.5\n",
    "for i in range(0,6):\n",
    "    for j in range(0,6):\n",
    "        for k in range(0,6):\n",
    "            if i+k+j!=0:\n",
    "                y_ens=ensembles([y_predict_plr,y_predict_nbg,y_predict_gbc],[i+0.0,j+0.0,k+0.0])\n",
    "                auc=roc_auc_score(y_test,y_ens)\n",
    "                if auc>auc_max:\n",
    "                    auc_max=auc\n",
    "                    maxi=i\n",
    "                    maxj=j\n",
    "                    maxk=k\n",
    "print auc_max,maxi,maxj,maxk\n",
    "\n",
    "#auc_max,maxi,maxj 0.7952718796 2 3\n",
    "#0.795813061279 4 5 1 with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rank ensembles\n",
    "def rank_pred(y):\n",
    "    y_pred=pd.DataFrame(y)\n",
    "    y_pred.columns=['y_pred']\n",
    "    y_pred_sorted=y_pred.sort(columns='y_pred').reset_index()\n",
    "    y_pred_sorted['rank']=pd.Series(np.zeros(len(y_pred)))\n",
    "    for i in range(len(y_pred_sorted)):\n",
    "        y_pred_sorted.set_value(i, 'rank', (i+0.0)/len(y_pred_sorted), takeable=False)\n",
    "    y_pred_fin=y_pred_sorted.sort(columns='index').reset_index(drop=True)\n",
    "    y_pred_rank=y_pred_fin['rank']\n",
    "    return y_pred_rank\n",
    "    #y_pred_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best.\n",
    "\n",
    "Models used:\n",
    "\n",
    "We used random forest and gradient boosted trees in this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=10, min_samples_split=10, min_samples_leaf=10, \n",
    "                       min_weight_fraction_leaf=0.0,max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                       bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, \n",
    "                       class_weight=None)\n",
    "#cross_val_score()\n",
    "#param_grid={'min_samples_split':np.linspace(1,1000,20)}\n",
    "#scores=cross_val_score(rf,data,y,cv=5,scoring='roc_auc')\n",
    "#print scores\n",
    "#print scores.mean()\n",
    "# try on whole data first\n",
    "rf.fit(data_train,y_train)\n",
    "y_predict_rf = rf.predict_proba(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = RFECV(rf, step=1, cv=2,scoring='roc_auc')\n",
    "selector = selector.fit(data_train, y_train)\n",
    "print selector.support_ \n",
    "print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=[]\n",
    "for i in range(len(selector.support_)):\n",
    "    if selector.support_[i]==False:\n",
    "        k.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores=cross_val_score(rf,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(data_train.drop(data_train.columns[[k]],axis=1),y_train)\n",
    "y_res_rf_train=rf.predict_proba(data_test.drop(data_test.columns[[k]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(data,y)\n",
    "y_res_rf=rf.predict_proba(holdout)\n",
    "\n",
    "output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "output['subscribed']=y_pred[:,1]\n",
    "output.to_csv(\"rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2=GradientBoostingClassifier(min_samples_leaf=20,min_samples_split=2,max_depth=3)\n",
    "#param_grid={'max_leaf_nodes':[None,5,10,15,25,50]}\n",
    "#gd=GridSearchCV(gbc2,param_grid=param_grid,scoring='roc_auc',cv=3)\n",
    "#gd.fit(data_train,y_train)\n",
    "#gd.best_params_ \n",
    "#scores=cross_val_score(gbc2,data.drop(data.columns[[k]],axis=1),y,cv=5,scoring='roc_auc')\n",
    "#scores\n",
    "#scores.mean()\n",
    "gbc2.fit(data_train,y_train)\n",
    "y_predict_gbc2 = gbc2.predict_proba(data_test)\n",
    "#roc_auc_score(y_test,y_predict_gbc2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = RFECV(gbc2, step=1, cv=2,scoring='roc_auc')\n",
    "selector = selector.fit(data_train, y_train)\n",
    "print selector.support_ \n",
    "print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print selector.support_\n",
    "kgbc=[]\n",
    "for i in range(len(selector.support_)):\n",
    "    if selector.support_[i]==False:\n",
    "        kgbc.append(i)\n",
    "kgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2.fit(data_train.drop(data_train.columns[[kgbc]],axis=1),y_train)\n",
    "y_res_gbc_train=gbc2.predict_proba(data_test.drop(data_test.columns[[kgbc]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2.fit(data,y)\n",
    "y_res_gbc=gbc2.predict_proba(holdout)\n",
    "\n",
    "output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "output['subscribed']=y_pred[:,1]\n",
    "output.to_csv(\"gbcdefault.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "#assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedprobs(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * y_predict_lr[:,1])  + (w2/(w1+w2+w3) * y_predict_gbc2[:,1]) + (w3/(w1+w2+w3) * y_predict_rf[:,1]))\n",
    "    return y_predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi=0\n",
    "maxj=0\n",
    "maxk=0\n",
    "maxl=0\n",
    "max=0\n",
    "for i in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    for j in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "        for k in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "                if i + j + k!=0:\n",
    "                    y_predict_ensemble = weightedprobs(i,j,k)\n",
    "                    auc = roc_auc_score(y_test,y_predict_ensemble)\n",
    "                    if auc>max:\n",
    "                        maxi = i\n",
    "                        maxj = j\n",
    "                        maxk = k\n",
    "                        max = auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', lr), ('rf', rf), ('gbc', gbc)], voting='soft',weights=[maxi,maxk,maxj])\n",
    "eclf.fit(data_train,y_train)\n",
    "y_predict_ensemble = eclf.predict_proba(data_test)\n",
    "roc_auc_score(y_test,y_predict_ensemble[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf.fit(data,y)\n",
    "y_pred=eclf.predict_proba(holdout)\n",
    "\n",
    "output=pd.DataFrame(hold_ids)\n",
    "#output['ID']=hold_ids\n",
    "output['subscribed']=y_pred[:,1]\n",
    "output.to_csv(\"ensemblefulldata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_pred(y):\n",
    "    y_pred=pd.DataFrame(y)\n",
    "    y_pred.columns=['y_pred']\n",
    "    y_pred_sorted=y_pred.sort(columns='y_pred').reset_index()\n",
    "    y_pred_sorted['rank']=pd.Series(np.zeros(len(y_pred)))\n",
    "    for i in range(len(y_pred_sorted)):\n",
    "        y_pred_sorted.set_value(i, 'rank', (i+0.0)/len(y_pred_sorted), takeable=False)\n",
    "    y_pred_fin=y_pred_sorted.sort(columns='index').reset_index(drop=True)\n",
    "    y_pred_rank=y_pred_fin['rank']\n",
    "    return y_pred_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_lr_rank = rank_pred(y_predict_lr[:,1])\n",
    "y_pred_gbc_rank = rank_pred(y_predict_gbc2[:,1])\n",
    "y_pred_rf_rank = rank_pred(y_predict_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_res_lr_rank = rank_pred(y_res_lr[:,1])\n",
    "y_res_gbc_rank = rank_pred(y_res_gbc[:,1])\n",
    "y_res_rf_rank = rank_pred(y_res_rf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedprobressrank(w1,w2,w3):\n",
    "    y_predict_ensemble =((w1/(w1+w2+w3) * y_res_lr_rank)  + (w2/(w1+w2+w3) * y_res_gbc_rank) + (w3/(w1+w2+w3) * y_res_rf_rank))\n",
    "    return y_predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_ensemble_rank = weightedprobressrank(maxi,maxj,maxk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 - Resampling strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791630005992\n",
      "0.790642335204\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "under_pipe=make_pipeline_imb(RandomUnderSampler(),LogisticRegression())\n",
    "scores=cross_val_score(under_pipe,X.drop(X.columns[k],axis=1),y,cv=5,scoring='roc_auc')\n",
    "print scores.mean()\n",
    "print cross_val_score(LogisticRegression(),X.drop(X.columns[k],axis=1),y,cv=5,scoring='roc_auc').mean()\n",
    "\n",
    "#Improvement of 0.001 in AUC"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
